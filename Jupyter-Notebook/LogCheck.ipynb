{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well log availability check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import lasio\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import merge_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-1.las\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-2.las\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-3.las\n"
     ]
    }
   ],
   "source": [
    "#use glob.glob to check the available well in our folder\n",
    "for filename in glob.iglob(r'C:\\Users\\Henky\\JUPYTER\\logChecker\\*.las', recursive=True):\n",
    "    print (filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-1.las Index(['CALI', 'DT', 'GR', 'ILD', 'MSFL', 'NPHI_LS', 'RHOB'], dtype='object')\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-2.las Index(['CALI', 'DT', 'GR', 'ILD', 'MSFL', 'NPHI_LS', 'RHOB'], dtype='object')\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\well-3.las Index(['CALI', 'DT', 'GR', 'ILD', 'MSFL', 'NPHI_LS', 'RHOB'], dtype='object')\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\another-well.las Index(['FORCE_2020_LITHOFACIES_CONFIDENCE', 'FORCE_2020_LITHOFACIES_LITHOLOGY',\n",
      "       'CALI', 'BS', 'DCAL', 'MUDWEIGHT', 'ROP', 'RDEP', 'RSHA', 'RMED', 'RXO',\n",
      "       'SP', 'DTCO', 'NPHI', 'PEF', 'GR', 'RHOB', 'DRHO', 'DEPTH_MD', 'X_LOC',\n",
      "       'Y_LOC', 'Z_LOC'],\n",
      "      dtype='object')\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\puk1.las Index(['CALI', 'DT', 'GR', 'ILD', 'MSFL', 'NPHI_LS', 'RHOB'], dtype='object')\n",
      "C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\well-try.las Index(['CALI', 'UNKNOWN:1', 'DEPTH', 'DRHO', 'DT', 'GR', 'ILD', 'UNKNOWN:2',\n",
      "       'MSFL', 'NPHI', 'UNKNOWN:3', 'UNKNOWN:4', 'RHOB', 'SFLU', 'SGR', 'SP',\n",
      "       'UNKNOWN:5', 'UNKNOWN:6', 'UNKNOWN:7', 'UNKNOWN:8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#simply add ** to the root directory to also access the subfolder under specified directory\n",
    "for filename in glob.iglob(r'C:\\Users\\Henky\\JUPYTER\\logChecker\\**\\*.las', recursive=True):\n",
    "    data=lasio.read(filename) #load data las using lasio\n",
    "    well_data=data.df()\n",
    "    print (filename, well_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have the report of the logs availability on our LAS files, let's improve the report format\n",
    "I wrote some functions to produce a better report format, we will use this functions to shorten our code writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    l = lasio.read(filename)\n",
    "    data_well = l.df()\n",
    "    log = list(data_well.columns.values)\n",
    "    wellname=filename.split('\\\\')\n",
    "    wellname=wellname[-1]\n",
    "    header = [{\n",
    "        'Well Name': wellname,\n",
    "        'START':l.well.STRT.value,\n",
    "        'STOP':l.well.STOP.value,\n",
    "        'STEP':l.well.STEP.value,\n",
    "        'Location': filename\n",
    "    }]\n",
    "    data_well['WELL'] = filename  \n",
    "    log_list = pd.DataFrame(header)\n",
    "    return data_well, log_list\n",
    "\n",
    "def merge_alias(db, alias, logs_selected):\n",
    "    well = db['WELL'].unique()\n",
    "    merged_data = pd.DataFrame()\n",
    "    for i in range(len(well)):\n",
    "        data = db.where(db['WELL']==well[i]).dropna(axis=1, how='all')\n",
    "        for j in range(len(alias)):\n",
    "            welllog_name = list(set(data.columns).intersection(alias.get(list(alias)[j])))\n",
    "            samelog = data[welllog_name]\n",
    "            count_log = dict(sorted(zip(welllog_name, samelog.count()), key=lambda item: item[1], reverse=True))\n",
    "            welllog_name = list(count_log.keys())\n",
    "            if (len(welllog_name)!=0):\n",
    "                #If more than one log aliases exist, normalize each log to have same data range in the same depth\n",
    "                if (len(welllog_name)>1):\n",
    "                    alias_logs = data[welllog_name].dropna()\n",
    "                    if (len(alias_logs)!=0):\n",
    "                        a = []; b = []; c = []\n",
    "                        for n in range(len(alias_logs.columns)):\n",
    "                            q1 = alias_logs[welllog_name[n]].quantile(0.1)\n",
    "                            q9 = alias_logs[welllog_name[n]].quantile(0.9)\n",
    "                            a.append(q1)\n",
    "                            b.append(q9)\n",
    "                            c = [b-a for (a,b) in zip(a,b)]\n",
    "                            c = list(map(lambda x: x/c[0],c))\n",
    "                        for n in range(len(welllog_name)):\n",
    "                            data.loc[:, welllog_name[n]] *= 1/c[n]\n",
    "                    for k in range(len(welllog_name)-1):\n",
    "                        data[welllog_name[0]].fillna(data[welllog_name[k+1]], inplace=True)\n",
    "                data[list(alias)[j]] = data[welllog_name[0]]   \n",
    "        merged_data = merged_data.append(data)\n",
    "        merged_data = merged_data[merged_data['WELL'].notna()]\n",
    "        new_list=[]\n",
    "        for x in logs_selected:\n",
    "            if x in list(merged_data.columns):\n",
    "                new_list.append(x)\n",
    "        merged_data = merged_data[new_list]\n",
    "    return merged_data, data\n",
    "\n",
    "def tablecheck(filename, logs_selected):\n",
    "    data_well, log_list=load_data(filename)\n",
    "    merged_data, data=merge_alias(data_well, alias, logs_selected)\n",
    "    df=pd.DataFrame([[\"X\"]*(len(list(merged_data.columns)))], columns=list(merged_data.columns))\n",
    "    df2=pd.concat([df, log_list], axis=1)\n",
    "    return df2, log_list\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-do the use of glob library and use the functions created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CAL RXO GR POR DRES   DT DENS DRHO         Well Name      START  \\\n",
      "0   X   X  X   X    X    X    X  NaN        well-1.las  3001.0000   \n",
      "1   X   X  X   X    X    X    X  NaN        well-2.las  3001.0000   \n",
      "2   X   X  X   X    X    X    X  NaN        well-3.las  3001.0000   \n",
      "3   X   X  X   X  NaN  NaN    X    X  another-well.las    25.0000   \n",
      "4   X   X  X   X    X    X    X  NaN          puk1.las  1860.0000   \n",
      "5   X   X  X   X    X    X    X    X      well-try.las   506.2728   \n",
      "\n",
      "          STOP   STEP                                           Location  \n",
      "0  4460.000000  0.500       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-1.las  \n",
      "1  4521.500000  0.500       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-2.las  \n",
      "2  4759.500000  0.500       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-3.las  \n",
      "3  3210.005615  0.152  C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\another-...  \n",
      "4  4918.000000  0.500     C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\puk1.las  \n",
      "5  1452.981600  0.000  C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\well-try...  \n"
     ]
    }
   ],
   "source": [
    "#I also put a library (JSON) to help us merge the log name and avoid the inconsistancy of the result\n",
    "\n",
    "with open('alias.json') as file:\n",
    "    alias = json.load(file) #load the JSON File\n",
    "    \n",
    "#define the logs that we are interested in our las files, check the name on the JSON library\n",
    "logs_selected= ['CAL', 'RXO', 'GR', 'POR', 'DRES', 'DT', 'DENS', 'DRHO'] \n",
    "\n",
    "#create an empty dataframe as the report container, use the glob library to explore folders, print the report\n",
    "df=pd.DataFrame(columns=logs_selected)\n",
    "for filename in glob.iglob(r'C:\\Users\\Henky\\JUPYTER\\logChecker\\**\\*.las', recursive=True):\n",
    "    df2, log_list=tablecheck(filename, logs_selected)\n",
    "    df=df.append(df2, ignore_index=True, sort=False)\n",
    "    logCheckReport=df #create the report from the df\n",
    "    \n",
    "#print the result    \n",
    "print (logCheckReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Well Name      START         STOP   STEP  \\\n",
      "0        well-1.las  3001.0000  4460.000000  0.500   \n",
      "1        well-2.las  3001.0000  4521.500000  0.500   \n",
      "2        well-3.las  3001.0000  4759.500000  0.500   \n",
      "3  another-well.las    25.0000  3210.005615  0.152   \n",
      "4          puk1.las  1860.0000  4918.000000  0.500   \n",
      "5      well-try.las   506.2728  1452.981600  0.000   \n",
      "\n",
      "                                            Location CAL RXO GR POR DRES   DT  \\\n",
      "0       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-1.las   X   X  X   X    X    X   \n",
      "1       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-2.las   X   X  X   X    X    X   \n",
      "2       C:\\Users\\Henky\\JUPYTER\\logChecker\\well-3.las   X   X  X   X    X    X   \n",
      "3  C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\another-...   X   X  X   X  NaN  NaN   \n",
      "4     C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\puk1.las   X   X  X   X    X    X   \n",
      "5  C:\\Users\\Henky\\JUPYTER\\logChecker\\new\\well-try...   X   X  X   X    X    X   \n",
      "\n",
      "  DENS DRHO  \n",
      "0    X  NaN  \n",
      "1    X  NaN  \n",
      "2    X  NaN  \n",
      "3    X    X  \n",
      "4    X  NaN  \n",
      "5    X    X  \n"
     ]
    }
   ],
   "source": [
    "#rearrange the order of the columns\n",
    "header=(list(log_list.columns)+logs_selected)\n",
    "logCheckReport=logCheckReport[header]\n",
    "print (logCheckReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the result as excel\n",
    "logCheckReport.to_excel(\"log checklist.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
